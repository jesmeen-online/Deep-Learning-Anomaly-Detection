{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "# Function to calculate the Excess Mass (EM) curve and Area Under the Curve (AUC)\n",
    "def em(t, t_max, volume_support, s_unif, s_X, n_generated):\n",
    "    EM_t = np.zeros(t.shape[0])  # Initialize the EM_t array with zeros\n",
    "    n_samples = s_X.shape[0]  # Get the number of samples in s_X\n",
    "    s_X_unique = np.unique(s_X)  # Get the unique values from s_X\n",
    "    EM_t[0] = 1.  # Set the first element of EM_t to 1\n",
    "\n",
    "    for u in s_X_unique:\n",
    "        # Update EM_t with the maximum value between the current EM_t and the new calculated value\n",
    "        EM_t = np.maximum(\n",
    "            EM_t,\n",
    "            1. / n_samples * (s_X > u).sum() -\n",
    "            t * (s_unif > u).sum() / n_generated * volume_support\n",
    "        )\n",
    "\n",
    "    # Find the index where EM_t is less than or equal to t_max\n",
    "    amax = np.argmax(EM_t <= t_max) + 1\n",
    "\n",
    "    # If amax is 1, it indicates t_max was not achieved\n",
    "    if amax == 1:\n",
    "        print('\\n failed to achieve t_max \\n')\n",
    "        amax = -1\n",
    "\n",
    "    # Calculate the AUC for the EM curve\n",
    "    AUC = auc(t[:amax], EM_t[:amax])\n",
    "    return AUC, EM_t, amax\n",
    "\n",
    "# Function to calculate the Mass Volume (MV) curve and Area Under the Curve (AUC)\n",
    "def mv(axis_alpha, volume_support, s_unif, s_X, n_generated):\n",
    "    n_samples = s_X.shape[0]  # Get the number of samples in s_X\n",
    "    s_X_argsort = np.argsort(s_X)  # Get the indices that would sort s_X\n",
    "    mass = 0  # Initialize mass to zero\n",
    "    cpt = 1  # Initialize counter to 1\n",
    "    u = s_X[s_X_argsort[-1]]  # Get the maximum value from s_X\n",
    "    mv = np.zeros(axis_alpha.shape[0])  # Initialize the mv array with zeros\n",
    "\n",
    "    # Iterate through axis_alpha values\n",
    "    for i in range(axis_alpha.shape[0]):\n",
    "        while cpt <= n_samples:  # Ensure that cpt is within bounds\n",
    "            u_index = -cpt\n",
    "            if -cpt >= len(s_X_argsort):\n",
    "                # Adjust index if out of bounds\n",
    "                u_index = -len(s_X_argsort)\n",
    "\n",
    "            u = s_X[s_X_argsort[u_index]]  # Get the value at the sorted index\n",
    "            mass = 1. / n_samples * cpt  # Calculate mass\n",
    "\n",
    "            if mass >= axis_alpha[i]:\n",
    "                break  # Exit the loop if the required mass is reached\n",
    "\n",
    "            cpt += 1\n",
    "\n",
    "        # Calculate mv value\n",
    "        mv[i] = float((s_unif >= u).sum()) / n_generated * volume_support\n",
    "\n",
    "    # Calculate the AUC for the MV curve\n",
    "    return auc(axis_alpha, mv), mv\n",
    "\n",
    "# Function for extending our data of values from previous timestamps (temporalization)\n",
    "def temporalize(X, y, lookback):\n",
    "    output_X = []  # Initialize list for temporalized input data\n",
    "    output_y = []  # Initialize list for temporalized output data\n",
    "\n",
    "    # Iterate through the data, creating temporal sequences\n",
    "    for i in range(len(X) - lookback - 1):\n",
    "        t = []  # Initialize list for a single temporal sequence\n",
    "        for j in range(1, lookback + 1):\n",
    "            # Gather past records up to the lookback period\n",
    "            t.append(X[i + j - 1])\n",
    "        output_X.append(t)  # Append the sequence to the output_X list\n",
    "        output_y.append(y[i + lookback + 1])  # Append the corresponding y value to output_y\n",
    "\n",
    "    # Convert lists to numpy arrays and return them\n",
    "    return np.array(output_X), np.array(output_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyod\n",
    "\n",
    "name=\"\"\n",
    "folder=\"A2Benchmark\"\n",
    "file_path = 'data/'+folder+'/'\n",
    "\n",
    "method='using yahoo synthetic data by temporalize+percentile+CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "evaluation_df = pd.DataFrame(all_evaluation_metrics)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "evaluation_df.to_csv('csvfoldersynthetic/evaluation_metrics_'+method+'.csv', index=False)   "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
